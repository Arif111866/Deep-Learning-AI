{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNnEfGqc78GQyJ5ZxhtTAeQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arif111866/Deep-Learning-AI/blob/main/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MljIyLxZkqGf",
        "outputId": "1db9a192-f5c7-4011-ffbf-5ba6dcf0e6a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Input\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# 1. Load and preprocess MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.\n",
        "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = Input(shape=(784,))\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "x = layers.Dense(16, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "model = models.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "metadata": {
        "id": "LvAeDzfblRg6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Set loss and optimizer\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# 4. Training loop with tf.GradientTape()\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nStart of epoch {epoch+1}\")\n",
        "    for step, (x_batch, y_batch) in enumerate(train_ds):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch, training=True)\n",
        "            loss_value = loss_fn(y_batch, logits)\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}: loss = {loss_value.numpy():.4f}\")\n",
        "\n",
        "# 5. Evaluate on test set\n",
        "test_logits = model(x_test, training=False)\n",
        "test_acc = tf.keras.metrics.sparse_categorical_accuracy(y_test, test_logits)\n",
        "print(f\"\\nTest accuracy (tf.GradientTape): {tf.reduce_mean(test_acc).numpy():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk8Ah9lalUoz",
        "outputId": "fd9f88ab-1488-4c40-a551-1deb04591136"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 1\n",
            "Step 0: loss = 2.3606\n",
            "Step 100: loss = 0.4854\n",
            "Step 200: loss = 0.4229\n",
            "Step 300: loss = 0.2681\n",
            "Step 400: loss = 0.2635\n",
            "\n",
            "Start of epoch 2\n",
            "Step 0: loss = 0.2044\n",
            "Step 100: loss = 0.1541\n",
            "Step 200: loss = 0.2174\n",
            "Step 300: loss = 0.1580\n",
            "Step 400: loss = 0.1704\n",
            "\n",
            "Start of epoch 3\n",
            "Step 0: loss = 0.1321\n",
            "Step 100: loss = 0.1083\n",
            "Step 200: loss = 0.1602\n",
            "Step 300: loss = 0.1253\n",
            "Step 400: loss = 0.1320\n",
            "\n",
            "Start of epoch 4\n",
            "Step 0: loss = 0.1102\n",
            "Step 100: loss = 0.0923\n",
            "Step 200: loss = 0.1238\n",
            "Step 300: loss = 0.1085\n",
            "Step 400: loss = 0.1156\n",
            "\n",
            "Start of epoch 5\n",
            "Step 0: loss = 0.0924\n",
            "Step 100: loss = 0.0776\n",
            "Step 200: loss = 0.0979\n",
            "Step 300: loss = 0.0985\n",
            "Step 400: loss = 0.1058\n",
            "\n",
            "Test accuracy (tf.GradientTape): 0.9644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuild the same model\n",
        "inputs2 = Input(shape=(784,))\n",
        "x2 = layers.Dense(64, activation='relu')(inputs2)\n",
        "x2 = layers.Dense(32, activation='relu')(x2)\n",
        "x2 = layers.Dense(16, activation='relu')(x2)\n",
        "outputs2 = layers.Dense(10, activation='softmax')(x2)\n",
        "model2 = models.Model(inputs=inputs2, outputs=outputs2)\n",
        "\n",
        "# Compile and train using .fit\n",
        "model2.compile(optimizer='adam',\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model2.fit(x_train, y_train, epochs=5, batch_size=128, verbose=2)\n",
        "\n",
        "# Evaluate on test data\n",
        "loss, acc = model2.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"\\nTest accuracy (model.fit): {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICkRWNwHlXZ-",
        "outputId": "4c8c589d-35e3-4d38-ccb1-c8ee546023f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 - 5s - 10ms/step - accuracy: 0.8418 - loss: 0.5155\n",
            "Epoch 2/5\n",
            "469/469 - 1s - 2ms/step - accuracy: 0.9439 - loss: 0.1896\n",
            "Epoch 3/5\n",
            "469/469 - 1s - 3ms/step - accuracy: 0.9581 - loss: 0.1412\n",
            "Epoch 4/5\n",
            "469/469 - 1s - 3ms/step - accuracy: 0.9653 - loss: 0.1144\n",
            "Epoch 5/5\n",
            "469/469 - 1s - 2ms/step - accuracy: 0.9718 - loss: 0.0950\n",
            "\n",
            "Test accuracy (model.fit): 0.9673\n"
          ]
        }
      ]
    }
  ]
}